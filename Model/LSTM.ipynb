{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W_mw9FztF-Li"
      },
      "outputs": [],
      "source": [
        "from tensorflow import data, size\n",
        "\n",
        "from keras import Sequential, losses, metrics, optimizers\n",
        "from keras.backend import clear_session\n",
        "from keras.layers import LSTM, InputLayer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import config as c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qQI4SWVlF-Lm"
      },
      "outputs": [],
      "source": [
        "def csv_to_tensor(target=c.input, step=c.step, take=None):\n",
        "    sub_dataset = []\n",
        "    for file in os.listdir(target)[:take]:\n",
        "        df = pd.read_csv(os.path.join(target, file))\n",
        "\n",
        "        df = data.Dataset.from_tensor_slices(df)\n",
        "        df = df.window(step, shift=1, drop_remainder=True).flat_map(\n",
        "            lambda x: x.batch(c.BATCH_SIZE))\n",
        "        sub_dataset.append(df)\n",
        "\n",
        "    tensor = sub_dataset[0]\n",
        "    for dataset in sub_dataset[1:]:\n",
        "        tensor = tensor.concatenate(dataset)\n",
        "    return tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdxWqh6mF-Ln",
        "outputId": "3aa54af2-d55a-46d2-d79b-5c8fdf9208d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data imported from: 10 videos\n"
          ]
        }
      ],
      "source": [
        "take = 10\n",
        "inputs = csv_to_tensor(target=c.input, take=take)\n",
        "outputs = csv_to_tensor(target=c.output, take=take)\n",
        "\n",
        "print('Data imported from:', take, 'videos')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgnU824BF-Lp",
        "outputId": "f3024e2b-35d9-4708-9314-e3b8a2524479"
      },
      "outputs": [],
      "source": [
        "dataset = data.Dataset.zip((inputs, outputs))\n",
        "\n",
        "train_dataset = dataset.take(4000).shuffle(c.BUFFER_SIZE).batch(\n",
        "    c.BATCH_SIZE).prefetch(data.experimental.AUTOTUNE)\n",
        "val_dataset = dataset.skip(4000).batch(\n",
        "    c.BATCH_SIZE).prefetch(data.experimental.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"food_frame_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 64)          147712    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 4)           1104      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 1)           24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,840\n",
            "Trainable params: 148,840\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "clear_session()\n",
        "\n",
        "model = Sequential(name='food_frame_classification')\n",
        "model.add(InputLayer(input_shape=(None, c.features)))\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(4, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(1, return_sequences=True, activation='relu'))\n",
        "\n",
        "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=optimizers.Adam(),\n",
        "              metrics=metrics.Accuracy('val_accuracy'),\n",
        "              run_eagerly=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwcHeG9aF-Lq",
        "outputId": "95a0b6e8-66e2-46e8-9e2b-d89a40106c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.6886 - val_accuracy: 0.6393 - val_loss: 0.7201 - val_val_accuracy: 0.5600\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.6473 - val_accuracy: 0.5035 - val_loss: 0.7386 - val_val_accuracy: 0.5188\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.6071 - val_accuracy: 0.4999 - val_loss: 0.8527 - val_val_accuracy: 0.5172\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5792 - val_accuracy: 0.5312 - val_loss: 0.8217 - val_val_accuracy: 0.5668\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.5644 - val_accuracy: 0.5732 - val_loss: 1.0712 - val_val_accuracy: 0.5539\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5508 - val_accuracy: 0.5940 - val_loss: 0.9813 - val_val_accuracy: 0.6181\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.5421 - val_accuracy: 0.6161 - val_loss: 1.1046 - val_val_accuracy: 0.5894\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5397 - val_accuracy: 0.6359 - val_loss: 1.2783 - val_val_accuracy: 0.6133\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.5339 - val_accuracy: 0.6465 - val_loss: 1.3751 - val_val_accuracy: 0.6328\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.5316 - val_accuracy: 0.6617 - val_loss: 1.3309 - val_val_accuracy: 0.6387\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5300 - val_accuracy: 0.6673 - val_loss: 1.4468 - val_val_accuracy: 0.6651\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.5285 - val_accuracy: 0.6744 - val_loss: 1.4246 - val_val_accuracy: 0.6737\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5274 - val_accuracy: 0.6775 - val_loss: 1.6534 - val_val_accuracy: 0.6676\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5259 - val_accuracy: 0.6791 - val_loss: 1.8355 - val_val_accuracy: 0.6788\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5294 - val_accuracy: 0.6862 - val_loss: 2.0143 - val_val_accuracy: 0.6684\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.5327 - val_accuracy: 0.6805 - val_loss: 1.5708 - val_val_accuracy: 0.6966\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.5261 - val_accuracy: 0.6877 - val_loss: 1.5818 - val_val_accuracy: 0.7026\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.5410 - val_accuracy: 0.6966 - val_loss: 1.2645 - val_val_accuracy: 0.7247\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 8s 112ms/step - loss: 0.5265 - val_accuracy: 0.6804 - val_loss: 1.3484 - val_val_accuracy: 0.7143\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5240 - val_accuracy: 0.6869 - val_loss: 1.5645 - val_val_accuracy: 0.7025\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.5248 - val_accuracy: 0.6877 - val_loss: 1.6640 - val_val_accuracy: 0.7014\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.5229 - val_accuracy: 0.6951 - val_loss: 1.8436 - val_val_accuracy: 0.7058\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 8s 112ms/step - loss: 0.5225 - val_accuracy: 0.6949 - val_loss: 1.6831 - val_val_accuracy: 0.7213\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.5226 - val_accuracy: 0.6963 - val_loss: 1.9890 - val_val_accuracy: 0.6959\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 8s 112ms/step - loss: 0.5222 - val_accuracy: 0.6970 - val_loss: 2.0050 - val_val_accuracy: 0.7131\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 8s 112ms/step - loss: 0.5228 - val_accuracy: 0.6999 - val_loss: 2.0811 - val_val_accuracy: 0.6987\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5204 - val_accuracy: 0.6996 - val_loss: 2.4851 - val_val_accuracy: 0.7030\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 8s 113ms/step - loss: 0.5224 - val_accuracy: 0.7018 - val_loss: 2.2867 - val_val_accuracy: 0.7151\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 8s 113ms/step - loss: 0.5209 - val_accuracy: 0.7042 - val_loss: 2.3960 - val_val_accuracy: 0.7018\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 8s 113ms/step - loss: 0.5190 - val_accuracy: 0.7009 - val_loss: 2.4216 - val_val_accuracy: 0.7062\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 7s 101ms/step - loss: 0.5181 - val_accuracy: 0.7012 - val_loss: 2.7323 - val_val_accuracy: 0.7050\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 8s 114ms/step - loss: 0.5179 - val_accuracy: 0.7036 - val_loss: 2.5587 - val_val_accuracy: 0.7117\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.5192 - val_accuracy: 0.7032 - val_loss: 2.5828 - val_val_accuracy: 0.7152\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5177 - val_accuracy: 0.7063 - val_loss: 2.8977 - val_val_accuracy: 0.6901\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5174 - val_accuracy: 0.7040 - val_loss: 2.3748 - val_val_accuracy: 0.7411\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5184 - val_accuracy: 0.7067 - val_loss: 2.5375 - val_val_accuracy: 0.7162\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5149 - val_accuracy: 0.7053 - val_loss: 2.8604 - val_val_accuracy: 0.7052\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5130 - val_accuracy: 0.7025 - val_loss: 2.7097 - val_val_accuracy: 0.7056\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5100 - val_accuracy: 0.7050 - val_loss: 2.6008 - val_val_accuracy: 0.7285\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5091 - val_accuracy: 0.7033 - val_loss: 2.6039 - val_val_accuracy: 0.7299\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.5082 - val_accuracy: 0.7058 - val_loss: 3.0889 - val_val_accuracy: 0.7016\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.5094 - val_accuracy: 0.7092 - val_loss: 2.5961 - val_val_accuracy: 0.7139\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5073 - val_accuracy: 0.7074 - val_loss: 2.7744 - val_val_accuracy: 0.7160\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5062 - val_accuracy: 0.7086 - val_loss: 3.0750 - val_val_accuracy: 0.7032\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5113 - val_accuracy: 0.7085 - val_loss: 2.2141 - val_val_accuracy: 0.7193\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5075 - val_accuracy: 0.7011 - val_loss: 2.7037 - val_val_accuracy: 0.6952\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.5070 - val_accuracy: 0.7065 - val_loss: 3.0230 - val_val_accuracy: 0.7071\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.5066 - val_accuracy: 0.7059 - val_loss: 2.2966 - val_val_accuracy: 0.7347\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5042 - val_accuracy: 0.7089 - val_loss: 2.8528 - val_val_accuracy: 0.7319\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5036 - val_accuracy: 0.7092 - val_loss: 2.8874 - val_val_accuracy: 0.7225\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5034 - val_accuracy: 0.7068 - val_loss: 2.8948 - val_val_accuracy: 0.7264\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5031 - val_accuracy: 0.7074 - val_loss: 2.9127 - val_val_accuracy: 0.7259\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5025 - val_accuracy: 0.7099 - val_loss: 2.6116 - val_val_accuracy: 0.7375\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.5032 - val_accuracy: 0.7089 - val_loss: 2.7284 - val_val_accuracy: 0.7330\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5048 - val_accuracy: 0.7092 - val_loss: 2.9320 - val_val_accuracy: 0.7252\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.5034 - val_accuracy: 0.7099 - val_loss: 2.8639 - val_val_accuracy: 0.7282\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 9s 131ms/step - loss: 0.5024 - val_accuracy: 0.7085 - val_loss: 3.0638 - val_val_accuracy: 0.7208\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.5031 - val_accuracy: 0.7096 - val_loss: 3.0324 - val_val_accuracy: 0.7164\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 8s 111ms/step - loss: 0.5020 - val_accuracy: 0.7092 - val_loss: 3.1757 - val_val_accuracy: 0.7137\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 8s 113ms/step - loss: 0.5023 - val_accuracy: 0.7110 - val_loss: 3.3160 - val_val_accuracy: 0.7060\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 8s 111ms/step - loss: 0.5021 - val_accuracy: 0.7071 - val_loss: 3.2257 - val_val_accuracy: 0.7182\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 8s 123ms/step - loss: 0.5014 - val_accuracy: 0.7103 - val_loss: 3.4161 - val_val_accuracy: 0.7160\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.5010 - val_accuracy: 0.7111 - val_loss: 3.1072 - val_val_accuracy: 0.7222\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5016 - val_accuracy: 0.7110 - val_loss: 2.9682 - val_val_accuracy: 0.7222\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5019 - val_accuracy: 0.7099 - val_loss: 3.5068 - val_val_accuracy: 0.7091\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.5016 - val_accuracy: 0.7089 - val_loss: 2.8237 - val_val_accuracy: 0.7244\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5016 - val_accuracy: 0.7099 - val_loss: 2.7303 - val_val_accuracy: 0.7322\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.5018 - val_accuracy: 0.7109 - val_loss: 2.9248 - val_val_accuracy: 0.7292\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.5031 - val_accuracy: 0.7093 - val_loss: 3.5491 - val_val_accuracy: 0.7226\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 8s 125ms/step - loss: 0.5018 - val_accuracy: 0.7122 - val_loss: 3.1645 - val_val_accuracy: 0.7282\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 9s 127ms/step - loss: 0.5016 - val_accuracy: 0.7113 - val_loss: 3.0926 - val_val_accuracy: 0.7303\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.5014 - val_accuracy: 0.7115 - val_loss: 3.3530 - val_val_accuracy: 0.7225\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.5002 - val_accuracy: 0.7119 - val_loss: 3.6931 - val_val_accuracy: 0.7067\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.4990 - val_accuracy: 0.7108 - val_loss: 3.7427 - val_val_accuracy: 0.7063\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 8s 111ms/step - loss: 0.4986 - val_accuracy: 0.7121 - val_loss: 3.6352 - val_val_accuracy: 0.7125\n",
            "Epoch 76/100\n",
            "62/63 [============================>.] - ETA: 0s - loss: 0.4994 - val_accuracy: 0.7140"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save('saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Code\\Python\\AIP391\\Model\\LSTM.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Python/AIP391/Model/LSTM.ipynb#ch0000006?line=0'>1</a>\u001b[0m predict, _ \u001b[39m=\u001b[39m csv_to_tensor(target\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39minput, take\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Python/AIP391/Model/LSTM.ipynb#ch0000006?line=1'>2</a>\u001b[0m len_p \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(predict)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Python/AIP391/Model/LSTM.ipynb#ch0000006?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(len_p)\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "predict, _ = csv_to_tensor(target=c.input, take=1)\n",
        "len_p = list(predict)\n",
        "print(len_p)\n",
        "predict = predict.batch(len_p).batch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrNrByu3sZAO"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"food_frame_classification\" is incompatible with the layer: expected shape=(None, None, 512), found shape=(1, 1, 5, 512)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Code\\Python\\AIP391\\Model\\LSTM.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Python/AIP391/Model/LSTM.ipynb#ch0000007?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(predict)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Python/AIP391/Model/LSTM.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mround(result)))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py:264\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m   \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    265\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    266\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    267\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"food_frame_classification\" is incompatible with the layer: expected shape=(None, None, 512), found shape=(1, 1, 5, 512)"
          ]
        }
      ],
      "source": [
        "result = model.predict(predict)\n",
        "print(int(np.round(result)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
